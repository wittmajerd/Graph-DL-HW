{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.datasets import QM9\n",
        "\n",
        "from dataset import create_QM9_pyg_datasets\n",
        "from models import GCNModel, GATModel, GINModel, MPNNModel, SchNetModel, DimeNetPlusPlusModel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_model_name = \"DimeNet\"     # \"GCN\", \"GAT\", \"GIN\", \"MPNN\", \"SchNet\", \"DimeNet\"\n",
        "hcs = 64\n",
        "num_layers = 2\n",
        "heads = 8\n",
        "dropout = 0.5\n",
        "\n",
        "num_epochs = 100\n",
        "patience = 5\n",
        "best_model_path = f'./best_{selected_model_name}_model.pth' # Path to save the best model\n",
        "\n",
        "# For HOMO and LUMO (indices 2 and 3 in QM9's 19 targets)\n",
        "target_idx = [2, 3] # HOMO at index 2, LUMO at index 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Original QM9 dataset size: 130831\n",
            "Using subset of size: 50000\n",
            "Train PyG graphs: 40000\n",
            "Validation PyG graphs: 5000\n",
            "Test PyG graphs: 5000\n",
            "Number of node features: 11\n",
            "Number of edge features: 4\n",
            "Number of targets: 2\n",
            "\n",
            "Selected model: DimeNet\n",
            "DimeNetPlusPlusModel(\n",
            "  (dimenet): DimeNetPlusPlus(\n",
            "    (rbf): BesselBasisLayer(\n",
            "      (envelope): Envelope()\n",
            "    )\n",
            "    (sbf): SphericalBasisLayer(\n",
            "      (envelope): Envelope()\n",
            "    )\n",
            "    (emb): EmbeddingBlock(\n",
            "      (emb): Embedding(95, 64)\n",
            "      (lin_rbf): Linear(in_features=6, out_features=64, bias=True)\n",
            "      (lin): Linear(in_features=192, out_features=64, bias=True)\n",
            "    )\n",
            "    (output_blocks): ModuleList(\n",
            "      (0-4): 5 x OutputPPBlock(\n",
            "        (lin_rbf): Linear(in_features=6, out_features=64, bias=False)\n",
            "        (lin_up): Linear(in_features=64, out_features=256, bias=False)\n",
            "        (lins): ModuleList(\n",
            "          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (lin): Linear(in_features=256, out_features=64, bias=False)\n",
            "      )\n",
            "    )\n",
            "    (interaction_blocks): ModuleList(\n",
            "      (0-3): 4 x InteractionPPBlock(\n",
            "        (lin_rbf1): Linear(in_features=6, out_features=8, bias=False)\n",
            "        (lin_rbf2): Linear(in_features=8, out_features=64, bias=False)\n",
            "        (lin_sbf1): Linear(in_features=42, out_features=8, bias=False)\n",
            "        (lin_sbf2): Linear(in_features=8, out_features=64, bias=False)\n",
            "        (lin_kj): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (lin_ji): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (lin_down): Linear(in_features=64, out_features=64, bias=False)\n",
            "        (lin_up): Linear(in_features=64, out_features=64, bias=False)\n",
            "        (layers_before_skip): ModuleList(\n",
            "          (0): ResidualLayer(\n",
            "            (lin1): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (lin): Linear(in_features=64, out_features=64, bias=True)\n",
            "        (layers_after_skip): ModuleList(\n",
            "          (0-1): 2 x ResidualLayer(\n",
            "            (lin1): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (lin2): Linear(in_features=64, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Data Loading ---\n",
        "# train_graphs, val_graphs, test_graphs are lists of PyG Data objects\n",
        "# y_train, y_val, y_test are tensors of the selected targets, useful for knowing num_targets\n",
        "train_graphs, val_graphs, test_graphs = create_QM9_pyg_datasets(\n",
        "    train_ratio = 0.8,\n",
        "    val_ratio = 0.1,\n",
        "    test_ratio = 0.1,\n",
        "    subset_size = 50000,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_graphs, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)\n",
        "\n",
        "# --- Determine Model Input/Output Sizes ---\n",
        "# Get number of node and edge features from the dataset\n",
        "# Load a temporary full dataset instance just for these properties if needed,\n",
        "# or get from the first graph if the subset is representative.\n",
        "if train_graphs:\n",
        "    num_node_features = train_graphs[0].num_node_features\n",
        "    num_edge_features = train_graphs[0].num_edge_features\n",
        "else: # Fallback if subset is empty, though create_QM9_pyg_datasets should handle this\n",
        "    temp_dataset = QM9(root='./data/QM9')\n",
        "    num_node_features = temp_dataset.num_node_features\n",
        "    num_edge_features = temp_dataset.num_edge_features\n",
        "    del temp_dataset\n",
        "\n",
        "num_targets = len(target_idx)\n",
        "\n",
        "print(f\"Number of node features: {num_node_features}\")\n",
        "print(f\"Number of edge features: {num_edge_features}\") # Relevant for MPNN\n",
        "print(f\"Number of targets: {num_targets}\")\n",
        "\n",
        "# --- Model Initialization (Choose one model to train) ---\n",
        "\n",
        "if selected_model_name == \"GCN\":\n",
        "    model = GCNModel(num_node_features=num_node_features, hidden_channels=hcs, num_targets=num_targets, num_layers=num_layers, dropout_rate=dropout).to(device)\n",
        "elif selected_model_name == \"GAT\":\n",
        "    model = GATModel(num_node_features=num_node_features, hidden_channels=hcs, num_targets=num_targets, heads=heads, num_layers=num_layers, dropout_rate=dropout).to(device)\n",
        "elif selected_model_name == \"GIN\":\n",
        "    model = GINModel(num_node_features=num_node_features, hidden_channels=hcs, num_targets=num_targets, num_layers=num_layers, dropout_rate=dropout).to(device)\n",
        "elif selected_model_name == \"MPNN\":\n",
        "    model = MPNNModel(num_node_features=num_node_features, num_edge_features=num_edge_features, hidden_channels=hcs, num_targets=num_targets, num_layers=num_layers, dropout_rate=dropout).to(device)\n",
        "elif selected_model_name == \"SchNet\":\n",
        "    # SchNet uses atomic numbers (z) and positions (pos), not num_node_features directly for its core.\n",
        "    model = SchNetModel(num_targets=num_targets, hidden_channels=hcs).to(device)\n",
        "elif selected_model_name == \"DimeNet\":\n",
        "    model = DimeNetPlusPlusModel(num_targets=num_targets, hidden_channels=hcs).to(device)\n",
        "else:\n",
        "    raise ValueError(f\"Unknown model name: {selected_model_name}\")\n",
        "\n",
        "print(f\"\\nSelected model: {selected_model_name}\")\n",
        "print(model)\n",
        "\n",
        "# --- Optimizer and Loss Function ---\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training for DimeNet...\n",
            "Early stopping patience: 5 epochs. Best model will be saved to: ./best_DimeNet_model.pth\n",
            "Epoch 01/100, Train Loss: 406167561.0307, Val Loss: 633.2098\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n",
            "Epoch 02/100, Train Loss: 411.7191, Val Loss: 209.2449\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n",
            "Epoch 03/100, Train Loss: 198.0721, Val Loss: 131.6537\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n",
            "Epoch 04/100, Train Loss: 92.0638, Val Loss: 46.3060\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n",
            "Epoch 05/100, Train Loss: 59.2568, Val Loss: 30.3079\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n",
            "Epoch 06/100, Train Loss: 40.5725, Val Loss: 29.8573\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n",
            "Epoch 07/100, Train Loss: 20.9630, Val Loss: 9.3431\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n",
            "Epoch 08/100, Train Loss: 17.9688, Val Loss: 11.2154\n",
            "    Validation loss did not improve for 1 epoch(s).\n",
            "Epoch 09/100, Train Loss: 15.0076, Val Loss: 5.4847\n",
            "    Validation loss improved. Saved new best model to ./best_DimeNet_model.pth\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEarly stopping patience: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpatience\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m epochs. Best model will be saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     train_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     val_loss = evaluate_epoch(model, val_loader, criterion, device, target_idx, selected_model_name)\n\u001b[32m     65\u001b[39m     train_losses.append(train_loss)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device, target_indices_list, model_type)\u001b[39m\n\u001b[32m     12\u001b[39m     out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mSchNet\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDimeNet\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported model type for training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\msc_1\\GraphDL\\Graph-DL-HW\\models.py:248\u001b[39m, in \u001b[36mDimeNetPlusPlusModel.forward\u001b[39m\u001b[34m(self, z, pos, batch)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_dimenetpp \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dimenet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# Return zeros or raise error if DimeNetPlusPlus is not available\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.zeros((batch.max().item() + \u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.linear.out_features), device=z.device)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m node_representation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdimenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m x = \u001b[38;5;28mself\u001b[39m.linear(node_representation)\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch_geometric\\nn\\models\\dimenet.py:710\u001b[39m, in \u001b[36mDimeNet.forward\u001b[39m\u001b[34m(self, z, pos, batch)\u001b[39m\n\u001b[32m    707\u001b[39m angle = torch.atan2(b, a)\n\u001b[32m    709\u001b[39m rbf = \u001b[38;5;28mself\u001b[39m.rbf(dist)\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m sbf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx_kj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[38;5;66;03m# Embedding block.\u001b[39;00m\n\u001b[32m    713\u001b[39m x = \u001b[38;5;28mself\u001b[39m.emb(z, rbf, i, j)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\wittd\\anaconda3\\envs\\graph_ml\\Lib\\site-packages\\torch_geometric\\nn\\models\\dimenet.py:119\u001b[39m, in \u001b[36mSphericalBasisLayer.forward\u001b[39m\u001b[34m(self, dist, angle, idx_kj)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, dist: Tensor, angle: Tensor, idx_kj: Tensor) -> Tensor:\n\u001b[32m    118\u001b[39m     dist = dist / \u001b[38;5;28mself\u001b[39m.cutoff\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     rbf = torch.stack([\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bessel_funcs], dim=\u001b[32m1\u001b[39m)\n\u001b[32m    120\u001b[39m     rbf = \u001b[38;5;28mself\u001b[39m.envelope(dist).unsqueeze(-\u001b[32m1\u001b[39m) * rbf\n\u001b[32m    122\u001b[39m     cbf = torch.stack([f(angle) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sph_funcs], dim=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<lambdifygenerated-47>:2\u001b[39m, in \u001b[36m_lambdifygenerated\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_lambdifygenerated\u001b[39m(x):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (-\u001b[32m1.44995111708104\u001b[39m*x**\u001b[32m6\u001b[39m*sin(\u001b[32m20.9834632873535\u001b[39m*x) - \u001b[32m1.45109379904189\u001b[39m*x**\u001b[32m5\u001b[39m*cos(\u001b[32m20.9834632873535\u001b[39m*x) + \u001b[32m0.691541610252893\u001b[39m*x**\u001b[32m4\u001b[39m*sin(\u001b[32m20.9834632873535\u001b[39m*x) + \u001b[32m0.197739029286841\u001b[39m*x**\u001b[32m3\u001b[39m*cos(\u001b[32m20.9834632873535\u001b[39m*x) - \u001b[32m0.0353383685843967\u001b[39m*x**\u001b[32m2\u001b[39m*sin(\u001b[32m20.9834632873535\u001b[39m*x) - \u001b[32m0.00370503237816459\u001b[39m*x*cos(\u001b[32m20.9834632873535\u001b[39m*x) + \u001b[32m0.000176569154835254\u001b[39m*\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m20.9834632873535\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)/x**\u001b[32m7\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "def train_epoch(model, loader, optimizer, criterion, device, target_indices_list, model_type):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass depends on the model type\n",
        "        if model_type in [\"GCN\", \"GAT\", \"GIN\"]:\n",
        "            out = model(data.x, data.edge_index, data.batch)\n",
        "        elif model_type == \"MPNN\":\n",
        "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        elif model_type in [\"SchNet\", \"DimeNet\"]:\n",
        "            out = model(data.z, data.pos, data.batch)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type for training: {model_type}\")\n",
        "\n",
        "        # Select the correct targets from data.y\n",
        "        # data.y is typically [batch_size, 1, num_all_qm9_targets]\n",
        "        # We need to make it [batch_size, num_selected_targets]\n",
        "        actual_y = data.y.squeeze(1)[:, target_indices_list] # Squeeze out the middle dim, then select\n",
        "        \n",
        "        loss = criterion(out, actual_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_epoch(model, loader, criterion, device, target_indices_list, model_type):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "\n",
        "        if model_type in [\"GCN\", \"GAT\", \"GIN\"]:\n",
        "            out = model(data.x, data.edge_index, data.batch)\n",
        "        elif model_type == \"MPNN\":\n",
        "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        elif model_type in [\"SchNet\", \"DimeNet\"]:\n",
        "            out = model(data.z, data.pos, data.batch)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model type for evaluation: {model_type}\")\n",
        "            \n",
        "        actual_y = data.y.squeeze(1)[:, target_indices_list]\n",
        "        loss = criterion(out, actual_y)\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "# --- Training ---\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Early Stopping and Best Model Saving parameters\n",
        "early_stopping_counter = 0\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "print(f\"\\nStarting training for {selected_model_name}...\")\n",
        "print(f\"Early stopping patience: {patience} epochs. Best model will be saved to: {best_model_path}\")\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device, target_idx, selected_model_name)\n",
        "    val_loss = evaluate_epoch(model, val_loader, criterion, device, target_idx, selected_model_name)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f'Epoch {epoch:02d}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Check for improvement in validation loss for early stopping and best model saving\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stopping_counter = 0 # Reset counter\n",
        "        # Save the best model\n",
        "        # torch.jit.script(model).save(best_model_path)\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f'    Validation loss improved. Saved new best model to {best_model_path}')\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        print(f'    Validation loss did not improve for {early_stopping_counter} epoch(s).')\n",
        "\n",
        "    if early_stopping_counter >= patience:\n",
        "        print(f'\\nEarly stopping triggered after {epoch} epochs due to no improvement in validation loss for {patience} epochs.')\n",
        "        break\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "\n",
        "# --- Final Evaluation on Test Set ---\n",
        "# Load the best model saved during training for final evaluation\n",
        "if os.path.exists(best_model_path):\n",
        "    print(f\"\\nLoading best model from {best_model_path} for final evaluation...\")\n",
        "    # model = torch.jit.load(best_model_path).to(device)\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "else:\n",
        "    print(\"\\nWarning: No best model was saved (or path is incorrect). Evaluating with the last model state.\")\n",
        "\n",
        "test_loss = evaluate_epoch(model, test_loader, criterion, device, target_idx, selected_model_name)\n",
        "print(f'Final Test Loss for {selected_model_name} (using best model): {test_loss:.4f}')\n",
        "\n",
        "# It's good practice to also plot train_losses and val_losses to visualize training\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(f'Training and Validation Loss for {selected_model_name}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "graph_ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
